# Oracle AI Voice Assistant Configuration
# This file contains all environment variables for the application
# Copy this file to .env and fill in your actual values

# ========== Spring Configuration ==========
SPRING_CLOUD_OCI_ENABLED=false

# ========== OpenAI Configuration ==========
OPENAI_KEY=your-openai-api-key-here
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4

# ========== OCI Configuration (Optional) ==========
# OCI_VISION_ENDPOINT=https://vision.aiservice.YOUR_REGION.oci.oraclecloud.com/20220125
# OCI_COMPARTMENT_ID=ocid1.compartment.oc1..YOUR_COMPARTMENT_ID

# ========== Host and Path Configuration ==========
AIHOLO_HOST_URL=http://localhost:80
AUDIO_DIR_PATH=C:/path/to/interactive-ai-holograms/latest-version/src/main/resources/static/audio-aiholo/
OUTPUT_FILE_PATH=C:/path/to/interactive-ai-holograms/latest-version/aiholo_output.txt

# ========== Langflow Configuration ==========
LANGFLOW_SERVER_URL=http://your-langflow-server:7860/api/
LANGFLOW_FLOW_ID=your-flow-id
LANGFLOW_API_KEY=your-langflow-api-key

# ========== Audio2Face Configuration (Optional) ==========
# IS_AUDIO2FACE=true

# ========== Remote API Poller Configuration (Optional) ==========
# REMOTE_API_URL=https://aiholo2.org/api/getValue
# REMOTE_API_USER=oracleai
# REMOTE_API_PASSWORD=oracleai

# ========== TTS Configuration ==========
# TTS_ENGINE options: GCP (Google Cloud), OCI (Oracle Cloud), COQUI (high-quality offline neural TTS)
TTS_ENGINE=COQUI
# TTS_QUALITY options for Coqui: FAST, BALANCED, QUALITY (QUALITY = highest offline quality)
TTS_QUALITY=QUALITY

# ========== Voice Gender Configuration ==========
# VOICE_GENDER options: MALE, FEMALE (default: FEMALE)
# Controls which voice is used for text-to-speech across all languages
# Can be changed at runtime via POST /aiholo/config/voiceGender?gender=MALE or FEMALE
VOICE_GENDER=FEMALE

# ========== Agentic AI Training Set Configuration ==========
# USING_AGENTIC_TRAINING_SET_FILE: Enable/disable usage of training set file for queries
# When true, DirectLLMAgent and DefaultFallbackAgent will use AGENTIC_TRAINING_SET_PATH as authoritative source
# When false, agents will use standard LLM responses without training set context
USING_AGENTIC_TRAINING_SET_FILE=false

# AGENTIC_TRAINING_SET_PATH: Path to Oracle + DoN Agentic AI Training Set file
# Can be a classpath resource (e.g., "oracle-navy-training-set.txt") or absolute file path
# Leave empty or unset to operate without specialized training data
AGENTIC_TRAINING_SET_PATH=oracle-navy-training-set.txt

# ========== Database Configuration ==========
DB_USER=vector
DB_PASSWORD=vector_101
DB_URL=jdbc:oracle:thin:@//10.10.51.55:1521/demo

# ========== Java and Maven Paths ==========
JAVA_HOME=C:\tools\jdk-21.0.2
MAVEN_HOME=C:\tools\apache-maven-3.9.6

# ========== Voice Assistant Configuration ==========
ENABLE_VOICE_ASSISTANT=false
# Voice assistant engine: "porcupine" or "openwakeword"
VOICE_ASSISTANT_ENGINE=porcupine

# Porcupine configuration (when VOICE_ASSISTANT_ENGINE=porcupine)
PORCUPINE_ACCESS_KEY=your-porcupine-access-key
KEYWORD_PATH=C:\interactive-ai-holograms\latest-version\wakeupwords\Hey-computer_en_windows_v4_0_0.ppn

# OpenWakeWord configuration (when VOICE_ASSISTANT_ENGINE=openwakeword)
# Requires Python with openwakeword installed: pip install openwakeword
# OPENWAKEWORD_SCRIPT_PATH=wakeupwords/openwakeword_bridge.py
# OPENWAKEWORD_MODEL=hey_jarvis

ENABLE_LANGUAGE_DETECTION=true
RESPONSE_LANGUAGE=same

# ========== Audio Device Configuration ==========
# Stream A → Unreal (Live Link Hub source)
AUDIO_DEVICE_A=CABLE Input (VB-Audio Virtual Cable)
# Stream B → Zoom (local speaker/secondary output)
AUDIO_DEVICE_B=Speakers (2- Axiim Link)
# other examples include... 'CABLE Input (VB-Audio Virtual Cable)' and 'Speakers (VB-Audio Voicemeeter VAIO)' 'Speakers (USB Audio)';
# Enable dual audio output (set to false to only play to AUDIO_DEVICE_A)
ENABLE_DUAL_AUDIO_OUTPUT=true
# Delay in milliseconds between Stream A and Stream B playback
AUDIO_DELAY_MS=500

# ========== Vector RAG Configuration ==========
# Spring AI models for vector RAG (reuses OPENAI_API_KEY above)
OPENAI_BASE_URL=https://api.openai.com
OPENAI_CHAT_MODEL=gpt-3.5-turbo
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002

# Vector store settings
VECTORRAG_TABLE_NAME=vector_store
VECTORRAG_DROP_AT_STARTUP=false
VECTORRAG_DISTANCE_METRIC=COSINE
VECTORRAG_TEMP_DIR=tempDir
